{
  "name": "syllabus",
  "path": "artificial intelligence/syllabus.md",
  "metadata": {
    "tags": [
      "ai"
    ],
    "success": true
  },
  "content": "The following is a learning syllabus generated by AI (and will be modified by me as I learn more).\n\n---\n\n## AI Engineering & Agentic Systems Syllabus\n\n### Module 1: The Transformer Architecture & LLM Foundations\n\n- __Research Focus:__ Understand the \"Attention\" mechanism. This is the heart of every modern LLM.\n- __Key Readings:__  _Attention Is All You Need_ (Vaswani et al.). Focus on the Encoder-Decoder structure.\n- __Concepts:__ Tokens, Embeddings, Context Windows, and Temperature.\n- __Learning Goal:__ Be able to explain how a model predicts the next token and why \"context length\" is a physical hardware constraint.\n\n### Module 2: Retrieval-Augmented Generation (RAG)\n\n- __Research Focus:__ How to solve the \"hallucination\" problem by giving LLMs a \"library\" to look at.\n- __Concepts:__\n    - __Vector Embeddings:__ Turning text into math.\n    - __Vector Databases:__ (Pinecone, Weaviate, or Milvus) for semantic search.\n    - __Chunking Strategies:__ How to split a 500-page book so the AI can find the right paragraph.\n- __Learning Goal:__ Understand the pipeline: User Query → Embedding → Vector Search → Augmented Prompt → LLM Response.\n\n### Module 3: Prompt Engineering & Frameworks\n\n- __Research Focus:__ Moving from basic chatting to programmatic control.\n- __Tools:__ __LangChain__ or __LlamaIndex__.\n- __Techniques:__ Chain-of-Thought (CoT), Few-shot prompting, and ReAct (Reason + Act) patterns.\n- __Learning Goal:__ Learn how to \"chain\" multiple AI calls together to solve complex problems that a single prompt can’t handle.\n\n### Module 4: Agents and Tool Use (The \"Cutting Edge\")\n\n- __Research Focus:__ How to give an LLM \"hands.\" (e.g., letting it run a Python script or search the web).\n- __Concepts:__ Function Calling, Agentic Loops, and Self-Correction.\n- __Learning Goal:__ Understand how an AI determines which tool to use and how it handles errors when a tool returns an unexpected result.\n\n---\n\n## Targeted Projects\n\nTo prove you're hireable, you need to show you can handle __data__ and __state__.\n\n### Project 1: The \"Compendium Oracle\" (RAG System)\n\nBuild a local tool that allows you to \"talk\" to your own tech compendium.\n\n- __Tech Stack:__ Python, LangChain, FAISS (for local vector storage), and OpenAI/Anthropic API.\n- __The Challenge:__ Ingest your notes (Markdown/PDFs), store them in a vector DB, and create a CLI tool that answers technical questions based _only_ on your notes.\n- __Why this works:__ It demonstrates you understand the most common AI pattern used in corporate environments today.\n\n### Project 2: Automated Security Auditor (Agentic Workflow)\n\nSince you have an interest in cybersecurity, build an agent that analyzes code for vulnerabilities.\n\n- __Tech Stack:__ Python, an LLM with Function Calling, and a static analysis tool (like Bandit or Semgrep).\n- __The Workflow:__ The agent \"reads\" a Python file, decides to run a security scan tool, interprets the tool's output, and then writes a \"patch\" to fix the security flaw.\n- __Why this works:__ It shows you can build __Agents__ that interact with the real world (running scripts/writing files), which is the primary direction AI engineering is heading in 2026.\n    \n\n---\n\n### Recommended Learning Resources\n\n- __DeepLearning.AI:__ \"Short Courses\" on LangChain and AI Agents (very practical).\n- __Andrejs Karpathy's \"Zero to Hero\":__ Specifically the video on building GPT from scratch (the gold standard for theoretical understanding).\n- __The \"Pinecone Learning Center\":__ Excellent for understanding vector math and retrieval.",
  "attachments": {}
}